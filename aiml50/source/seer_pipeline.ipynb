{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.60\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment, Datastore, Environment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register/Reference a Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'workspaceblobstore': <azureml.data.azure_storage_datastore.AzureBlobDatastore object at 0x7f926c220630>, 'workspacefilestore': <azureml.data.azure_storage_datastore.AzureFileDatastore object at 0x7f926c228048>, 'damoseerdata': <azureml.data.azure_storage_datastore.AzureBlobDatastore object at 0x7f926c228550>}\n"
     ]
    }
   ],
   "source": [
    "# workspace\n",
    "ws = Workspace.from_config(\n",
    "    path='./azureml-config.json')\n",
    "print(ws.datastores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#datastore = Datastore.register_azure_blob_container(workspace=ws, \n",
    "#                                             datastore_name='damoseerdata', \n",
    "#                                             container_name='seer-container',\n",
    "#                                             account_name='damoaimlstorage', \n",
    "#                                             account_key='',\n",
    "#                                             create_if_not_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azureml.data.azure_storage_datastore.AzureBlobDatastore object at 0x7f926c220278>\n",
      "AmlCompute(workspace=Workspace.create(name='damo-mlworkspace', subscription_id='bc202ec2-54ef-4576-b7fb-a961c983398e', resource_group='damo-aiml'), name=damoseercompute, id=/subscriptions/bc202ec2-54ef-4576-b7fb-a961c983398e/resourceGroups/damo-aiml/providers/Microsoft.MachineLearningServices/workspaces/damo-mlworkspace/computes/damoseercompute, type=AmlCompute, provisioning_state=Succeeded, location=australiaeast, tags=None)\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "datastore = ws.datastores['damoseerdata']\n",
    "\n",
    "# compute target\n",
    "compute = ws.compute_targets['damoseercompute']\n",
    "\n",
    "print(datastore)\n",
    "print(compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Pipeline!\n",
    "The following will be created and then run:\n",
    "  1. Pipeline Parameters\n",
    "  2. Data Process Step\n",
    "  3. Training Step\n",
    "  4. Model Registration Step\n",
    "  5. Pipeline registration\n",
    "  6. Submit the pipeline for execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Parameters\n",
    "We need to tell the Pipeline what it needs to learn to see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<azureml.pipeline.core.graph.PipelineParameter object at 0x7f926c23e320>, <azureml.data.datapath.DataPathComputeBinding object at 0x7f926c23e358>)\n"
     ]
    }
   ],
   "source": [
    "datapath = DataPath(datastore=datastore, path_on_datastore='hardware')\n",
    "data_path_pipeline_param = (PipelineParameter(name=\"data\", \n",
    "                                             default_value=datapath), \n",
    "                                             DataPathComputeBinding(mode='mount'))\n",
    "print(data_path_pipeline_param)\n",
    "\n",
    "# Configuration for data prep and training steps\n",
    "dataprepEnvironment = Environment.from_pip_requirements('dataprepenv', 'requirements-dataprepandtraining.txt')\n",
    "dataprepRunConfig = RunConfiguration()\n",
    "dataprepRunConfig.environment = dataprepEnvironment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Process Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azureml.pipeline.steps.python_script_step.PythonScriptStep object at 0x7f926c2205f8>\n"
     ]
    }
   ],
   "source": [
    "seer_tfrecords = PipelineData(\n",
    "    \"tfrecords_set\",\n",
    "    datastore=datastore,\n",
    "    is_directory=True\n",
    ")\n",
    "\n",
    "prepStep = PythonScriptStep(\n",
    "    'parse.py',\n",
    "    source_directory='.',\n",
    "    name='Data Preparation',\n",
    "    compute_target=compute,\n",
    "    arguments=[\"--source_path\", data_path_pipeline_param, \"--target_path\", seer_tfrecords],\n",
    "    runconfig=dataprepRunConfig,\n",
    "    inputs=[data_path_pipeline_param],\n",
    "    outputs=[seer_tfrecords]\n",
    ")\n",
    "\n",
    "print(prepStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n",
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azureml.pipeline.steps.estimator_step.EstimatorStep object at 0x7f926c228320>\n"
     ]
    }
   ],
   "source": [
    "seer_training = PipelineData(\n",
    "    \"train\",\n",
    "    datastore=datastore,\n",
    "    is_directory=True\n",
    ")\n",
    "\n",
    "train = Estimator(source_directory='.',\n",
    "                    compute_target=compute,\n",
    "                    entry_script='train.py',\n",
    "                    pip_requirements_file='requirements-dataprepandtraining.txt')\n",
    "\n",
    "trainStep = EstimatorStep(\n",
    "    name='Model Training',\n",
    "    estimator=train,\n",
    "    estimator_entry_script_arguments=[\"--source_path\", seer_tfrecords, \n",
    "                                    \"--target_path\", seer_training,\n",
    "                                    \"--epochs\", 10,\n",
    "                                    \"--batch\", 20,\n",
    "                                    \"--lr\", 0.001],\n",
    "    inputs=[seer_tfrecords],\n",
    "    outputs=[seer_training],\n",
    "    compute_target=compute\n",
    ")\n",
    "\n",
    "print(trainStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Model Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azureml.pipeline.steps.python_script_step.PythonScriptStep object at 0x7f926c23ebe0>\n"
     ]
    }
   ],
   "source": [
    "registerEnvironment = Environment.from_pip_requirements('registerenv', 'requirements-registration.txt')\n",
    "registerRunConfig = RunConfiguration()\n",
    "registerRunConfig.environment = registerEnvironment\n",
    "\n",
    "seer_model = PipelineData(\n",
    "    \"model\",\n",
    "    datastore=datastore,\n",
    "    is_directory=True\n",
    ")\n",
    "\n",
    "registerStep = PythonScriptStep(\n",
    "    'register.py',\n",
    "    source_directory='.',\n",
    "    name='Model Registration',\n",
    "    arguments=[\"--source_path\", seer_training, \n",
    "               \"--target_path\", seer_model],\n",
    "    inputs=[seer_training],\n",
    "    outputs=[seer_model],\n",
    "    compute_target=compute,\n",
    "    runconfig=registerRunConfig\n",
    ")\n",
    "\n",
    "print(registerStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and publish the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n",
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n",
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Data Preparation [245a32d6][bb74677f-84f0-4646-a63c-55d831860987], (This step will run and generate new outputs)\n",
      "Created step Model Training [ff56996a][884edd1b-e363-4a0d-b5e9-6d3a90fb0237], (This step will run and generate new outputs)\n",
      "Created step Model Registration [df06b3ce][13374cdd-5994-426e-983f-4c0de03d2c1b], (This step will run and generate new outputs)\n",
      "Created data reference damoseerdata_daf26998 for StepId [999c4b39][a1dc6fcc-1bc5-4644-859b-9cc91cdfb1d7], (Consumers of this data will generate new runs.)\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=[prepStep, trainStep, registerStep])\n",
    "\n",
    "published_pipeline = pipeline.publish(\n",
    "    name=\"Seer Pipeline\", \n",
    "    description=\"Transfer learned image classifier. Uses folders as labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run created with ID:  7103c1bc-807a-4e25-8874-e578511eb035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d9e1953c404a50b50970762b36b757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Submit the pipeline to be run\n",
    "pipeline_run = Experiment(ws, 'seer',).submit(published_pipeline)\n",
    "print('Run created with ID: ', pipeline_run.id)\n",
    "\n",
    "RunDetails(pipeline_run).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
